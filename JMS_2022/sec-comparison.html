<!DOCTYPE html>
<html lang="fr" xml:lang="fr">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 6 Comparaison des différentes méthodes | Estimation en temps réel de la tendance-cycle : apport de l’utilisation des filtres asymétriques dans la détection des points de retournement</title>
  <meta name="description" content="Journées de méthodologie statistique de l’Insee (JMS) / Mars 2022 / PARIS" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 6 Comparaison des différentes méthodes | Estimation en temps réel de la tendance-cycle : apport de l’utilisation des filtres asymétriques dans la détection des points de retournement" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Journées de méthodologie statistique de l’Insee (JMS) / Mars 2022 / PARIS" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 6 Comparaison des différentes méthodes | Estimation en temps réel de la tendance-cycle : apport de l’utilisation des filtres asymétriques dans la détection des points de retournement" />
  
  <meta name="twitter:description" content="Journées de méthodologie statistique de l’Insee (JMS) / Mars 2022 / PARIS" />
  

<meta name="author" content="Alain Quartier-la-Tente" />


<meta name="date" content="2022-03-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sec-nonparamreg.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stage 3A AQLT</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Résumé</a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="sec-SAtoTCE.html"><a href="sec-SAtoTCE.html"><i class="fa fa-check"></i><b>1</b> De la désaisonnalisation à l’estimation tendance-cycle</a></li>
<li class="chapter" data-level="2" data-path="sec-propMM.html"><a href="sec-propMM.html"><i class="fa fa-check"></i><b>2</b> Quelques propriétés sur les moyennes mobiles</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sec-propMM.html"><a href="sec-propMM.html#gain-et-fonction-de-déphasage"><i class="fa fa-check"></i><b>2.1</b> Gain et fonction de déphasage</a></li>
<li class="chapter" data-level="2.2" data-path="sec-propMM.html"><a href="sec-propMM.html#propriétés-souhaitables-dune-moyenne-mobile"><i class="fa fa-check"></i><b>2.2</b> Propriétés souhaitables d’une moyenne mobile</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sec-propMM.html"><a href="sec-propMM.html#préservation-de-tendances"><i class="fa fa-check"></i><b>2.2.1</b> Préservation de tendances</a></li>
<li class="chapter" data-level="2.2.2" data-path="sec-propMM.html"><a href="sec-propMM.html#réduction-du-bruit"><i class="fa fa-check"></i><b>2.2.2</b> Réduction du bruit</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sec-propMM.html"><a href="sec-propMM.html#sec-mmasym"><i class="fa fa-check"></i><b>2.3</b> Estimation en temps réel et moyennes mobiles asymétriques</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="sec-propMM.html"><a href="sec-propMM.html#subec:mmetprev"><i class="fa fa-check"></i><b>2.3.1</b> Moyennes mobiles asymétriques et prévision</a></li>
<li class="chapter" data-level="2.3.2" data-path="sec-propMM.html"><a href="sec-propMM.html#indicateurs-de-qualité-des-moyennes-mobiles-asymétriques"><i class="fa fa-check"></i><b>2.3.2</b> Indicateurs de qualité des moyennes mobiles asymétriques</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sec-theoriegen.html"><a href="sec-theoriegen.html"><i class="fa fa-check"></i><b>3</b> D’une théorie générale sur la construction des filtres asymétriques à l’approche FST</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sec-theoriegen.html"><a href="sec-theoriegen.html#subsec-theoriegen"><i class="fa fa-check"></i><b>3.1</b> Théorie générale de construction des filtres asymétriques</a></li>
<li class="chapter" data-level="3.2" data-path="sec-theoriegen.html"><a href="sec-theoriegen.html#subsec-GuggemosEtAl"><i class="fa fa-check"></i><b>3.2</b> Approche <em>Fidelity-Smoothness-Timeliness</em> (FST)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sec-WildiMcLeroy.html"><a href="sec-WildiMcLeroy.html"><i class="fa fa-check"></i><b>4</b> Filtres dépendant des données : trilemme ATS</a></li>
<li class="chapter" data-level="5" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html"><i class="fa fa-check"></i><b>5</b> Régression non paramétrique et régression polynomiale locale</a>
<ul>
<li class="chapter" data-level="5.1" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#sec-proietti"><i class="fa fa-check"></i><b>5.1</b> Régression polynomiale : approche de Proietti et Luati</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#filtres-symétriques"><i class="fa fa-check"></i><b>5.1.1</b> Filtres symétriques</a></li>
<li class="chapter" data-level="5.1.2" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#sec-kernels"><i class="fa fa-check"></i><b>5.1.2</b> Les différents noyaux</a></li>
<li class="chapter" data-level="5.1.3" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#sec-sympolyfilter"><i class="fa fa-check"></i><b>5.1.3</b> Quelques filtres symétriques particuliers</a></li>
<li class="chapter" data-level="5.1.4" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#subsec-lppasymf"><i class="fa fa-check"></i><b>5.1.4</b> Filtres asymétriques</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#subsec-lptimeliness"><i class="fa fa-check"></i><b>5.2</b> Extension avec le critère de <em>timeliness</em></a></li>
<li class="chapter" data-level="5.3" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#subsec-graythomson"><i class="fa fa-check"></i><b>5.3</b> Régression polynomiale : Gray et Thomson</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#filtres-symétriques-1"><i class="fa fa-check"></i><b>5.3.1</b> Filtres symétriques</a></li>
<li class="chapter" data-level="5.3.2" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#filtres-asymétriques"><i class="fa fa-check"></i><b>5.3.2</b> Filtres asymétriques</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#sec-rkhs"><i class="fa fa-check"></i><b>5.4</b> Reproducing Kernel Hilbert Space (RKHS) : approche de Dagum et Bianconcini</a></li>
<li class="chapter" data-level="5.5" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#subsec-equivlpfst"><i class="fa fa-check"></i><b>5.5</b> Liens entre les différentes méthodes</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#critères-de-gray-et-thomson-et-ceux-de-grun-rehomme-et-alii"><i class="fa fa-check"></i><b>5.5.1</b> Critères de Gray et Thomson et ceux de Grun-Rehomme <em>et alii</em></a></li>
<li class="chapter" data-level="5.5.2" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#équivalence-avec-les-moindres-carrés-pondérés"><i class="fa fa-check"></i><b>5.5.2</b> Équivalence avec les moindres carrés pondérés</a></li>
<li class="chapter" data-level="5.5.3" data-path="sec-nonparamreg.html"><a href="sec-nonparamreg.html#rkhs-et-polynômes-locaux"><i class="fa fa-check"></i><b>5.5.3</b> RKHS et polynômes locaux</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sec-comparison.html"><a href="sec-comparison.html"><i class="fa fa-check"></i><b>6</b> Comparaison des différentes méthodes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sec-comparison.html"><a href="sec-comparison.html#méthodologie"><i class="fa fa-check"></i><b>6.1</b> Méthodologie</a></li>
<li class="chapter" data-level="6.2" data-path="sec-comparison.html"><a href="sec-comparison.html#séries-simulées"><i class="fa fa-check"></i><b>6.2</b> Séries simulées</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="sec-comparison.html"><a href="sec-comparison.html#comparaison-des-filtres-polynomiaux-locaux-et-des-filtres-rkhs"><i class="fa fa-check"></i><b>6.2.1</b> Comparaison des filtres polynomiaux locaux et des filtres RKHS</a></li>
<li class="chapter" data-level="6.2.2" data-path="sec-comparison.html"><a href="sec-comparison.html#comparaison-avec-lapproche-fst"><i class="fa fa-check"></i><b>6.2.2</b> Comparaison avec l’approche FST</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sec-comparison.html"><a href="sec-comparison.html#série-réelle"><i class="fa fa-check"></i><b>6.3</b> Série réelle</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="appendix"><span><b>Annexe</b></span></li>
<li class="chapter" data-level="A" data-path="an-diag.html"><a href="an-diag.html"><i class="fa fa-check"></i><b>A</b> Synthèse des liens entre les différentes méthodes de construction de moyennes mobiles</a></li>
<li class="chapter" data-level="B" data-path="an-graphs.html"><a href="an-graphs.html"><i class="fa fa-check"></i><b>B</b> Coefficients, fonctions de gain et de déphasage</a></li>
<li class="chapter" data-level="C" data-path="an-equivfstlp.html"><a href="an-equivfstlp.html"><i class="fa fa-check"></i><b>C</b> Équivalence entre l’approche FST et les filtres polynomiaux locaux</a></li>
<li class="chapter" data-level="D" data-path="an-implicitforecasts.html"><a href="an-implicitforecasts.html"><i class="fa fa-check"></i><b>D</b> Prévisions implicites pour séries <code>RETAILx</code></a></li>
<li class="chapter" data-level="" data-path="références.html"><a href="références.html"><i class="fa fa-check"></i>Références</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estimation en temps réel de la tendance-cycle : apport de l’utilisation des filtres asymétriques dans la détection des points de retournement</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!-- <script type="text/x-mathjax-config"> -->
    <!-- MathJax.Hub.Config({ -->
            <!--   TeX: { -->
                    <!--     Macros: { -->
                            <!--       NN: "{\\mathbb{N}}", -->
                            <!--       ZZ: "{\\mathbb{Z}}", -->
                            <!--       QQ: "{\\mathbb{Q}}", -->
                            <!--       RR: "{\\mathbb{R}}", -->
                            <!--       shiftset: "{\\mathcal{D}}", -->
                            <!--       dx: ["{\\mathrm{d}^{#1}\\mspace{-1mu}\\mathord{#2}}", 2, ""], -->
                            <!--       indic: "{\\unicode{x1D7D9}}", -->
                            <!--       prob: "\\mathop{\\mathbb{P}}", -->
                            <!--       esp: "\\mathop{\\mathbb{E}}", -->
                            <!--       var: "\\mathop{\\mathbb{V}\\text{ar}}", -->
                            <!--       cov: "\\mathop{\\mathbb{C}\\text{ov}}", -->
                            <!--       PP: ["{\\prob\\left({#1}\\right)}", 1], -->
                            <!--       EE: ["{\\esp\\left[{#1}\\right]}", 1], -->
                            <!--       VV: ["{\\var\\left[{#1}\\right]}", 1], -->
                            <!--       CC: ["{\\cov\\left[{#1}\\right]}", 1], -->
                            <!--       normal: ["{\\mathcal{N}\\left({#1},{#2}\\right)}", 2], -->
                            <!--       ou: ["{#1}_{\\text{ou}}", 1], -->
                            <!--       oui: ["{#1}_{\\text{ou},#2}", 2], -->
                            <!--       pv: "{\\mathfrak{p}}", -->
                            <!--       qv: "{\\mathfrak{q}}", -->
                            <!--       zs: "{\\mathfrak{z}}", -->
                            <!--       ts: "{\\mathfrak{t}}", -->
                            <!--       sign: "{\\mathfrak{s}}", -->
                            <!--       shifts: "{\\delta}", -->
                            <!--       optim: "{\\beta}", -->
                            <!--       param: "{\\theta}", -->
                            <!--       unif: ["{\\mathcal{U}\\left({#1}\\right)}", 1], -->
                            <!--       argmin: "\\mathop{\\mathrm{argmin}}", -->
                            <!--       diag: "\\mathop{\\mathrm{Diag}}", -->
                            <!--       rang: "\\mathop{\\mathrm{rang}}", -->
                            <!--       pa: "\\mathop{\\mathrm{pa}}", -->
                            <!--       mrca: "\\mathop{\\mathrm{mrca}}", -->
                            <!--       desc: "\\mathop{\\mathrm{desc}}", -->
                            <!--       warning: ["\\color{red}{{#1}}", 1] -->
                            <!--     } -->
                    <!--   } -->
            <!-- }); -->
    <!-- </script> -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {Macros: {
            E: "{\\mathbb{E}}"
        },
        Augment: {
        Definitions: {
          delimiter: {
            "\\llbracket": '\u27E6',
            '\\rrbracket': '\u27E7'
          }}
        }}
    });
</script>
    <body>
    <div style="display:none" aria-hidden="true">
    \(
        \newcommand\R{\mathbb{R}}
        \newcommand\Z{\mathbb{Z}}
        \newcommand\LL{\mathbb{L}}
        \newcommand{\E}[1]{\mathbb{E}\left[#1\right]}
        \newcommand{\V}[1]{\mathbb{V}\left[#1\right]}
        \newcommand{\ps}[2]{\left\langle #1 \,,\, #2 \right\rangle}
        \newcommand\1{\mathbb{1}}
        \newcommand\N{\mathbb{N}}
        \newcommand\Norm{\mathcal{N}}
        \newcommand{\transp}[1]{{}^t\!#1}
        \newcommand\ud{\,\mathrm{d}}
        \DeclareMathOperator*{\argmax}{argmax}
        \DeclareMathOperator*{\argmin}{argmin}
        \DeclareMathOperator{\e}{e}
        \DeclareMathOperator{\Cov}{Cov}
        \DeclareMathOperator{\Determinant}{det}
        \newcommand{\determinant}[1]{\Determinant\left(#1\right)}
    \)
    </div>
    </body>
            
<div id="sec-comparison" class="section level1" number="6">
<h1><span class="header-section-number">Chapitre 6</span> Comparaison des différentes méthodes</h1>
<p>Les différentes méthode de construction de moyennes mobiles asymétriques sont comparées sur des données simulées et des données réelles.
Pour toutes les séries, un filtre symétrique de 13 termes est utilisé.
Ces méthodes sont également comparées aux estimations obtenues en prolongeant la série par un modèle ARIMA<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> puis en appliquant un filtre symétrique de Henderson de 13 termes.</p>
<div id="méthodologie" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Méthodologie</h2>
<p>En suivant une méthodologie proche de celle de <span class="citation"><a href="#ref-DarneDagum2009" role="doc-biblioref">Darne et Dagum</a> (<a href="#ref-DarneDagum2009" role="doc-biblioref">2009</a>)</span>, neuf séries mensuelles sont simulées entre janvier 1960 et décembre 2020 avec différent niveaux de variabilité. Chaque série simulée <span class="math inline">\(y_t= C_t+ T_t + I_t\)</span> peut s’écrire comme la somme de trois composantes :</p>
<ul>
<li><p>le cycle <span class="math inline">\(C_t = \rho [\cos (2 \pi t / \lambda) +\sin (2 \pi t / \lambda)]\)</span>, <span class="math inline">\(\lambda\)</span> est fixé à 72 (cycles de 6 ans, il y a donc 19 points de retournement détectables) ;</p></li>
<li><p>la tendance <span class="math inline">\(T_t = T_{t-1} + \nu_t\)</span> avec <span class="math inline">\(\nu_t \sim \mathcal{N}(0, \sigma_\nu^2)\)</span>, <span class="math inline">\(\sigma_\nu\)</span> étant fixé ) <span class="math inline">\(0,08\)</span> ;</p></li>
<li><p>et l’irrégulier <span class="math inline">\(I_t = e_t\)</span> avec <span class="math inline">\(e_t \sim \mathcal{N}(0, \sigma_e^2)\)</span>.</p></li>
</ul>
<p>Pour les différentes simulations, nous faisons varier les paramètre <span class="math inline">\(\rho\)</span> et <span class="math inline">\(\sigma_e^2\)</span> afin d’avoir d’avoir des séries avec différents rapports signal sur bruit :</p>
<ul>
<li><p>Fort rapport signal sur bruit (c’est-à-dire un I-C ratio faible et une faible variabilité) : <span class="math inline">\(\sigma_e^2=0,2\)</span> et <span class="math inline">\(\rho = 3,0,\, 3,5\)</span> ou <span class="math inline">\(4,0\)</span> (I-C ratio compris entre 0,9 et 0,7) ;</p></li>
<li><p>Rapport signal sur bruit moyen (c’est-à-dire un I-C ratio moyen et une variabilité moyenne) : <span class="math inline">\(\sigma_e^2=0,3\)</span> et <span class="math inline">\(\rho = 1,5,\, 2,0\)</span> ou <span class="math inline">\(3,0\)</span> (I-C ratio compris entre 2,3 et 1,4) ;</p></li>
<li><p>Faible rapport signal sur bruit (c’est-à-dire un I-C ratio fort et une forte variabilité) : <span class="math inline">\(\sigma_e^2=0,4\)</span> et <span class="math inline">\(\rho = 0,5,\, 0,7\)</span> ou <span class="math inline">\(1,0\)</span> (I-C ratio compris entre 8,9 et 5,2).</p></li>
</ul>
<p>Pour chaque série et chaque date, la tendance-cycle est estimée en utilisant les différentes méthodes présentées dans de ce rapport.
Pour les régressions polynomiales locales, les filtres asymétriques sont calibrés en utilisant l’I-C ratio estimé à chaque date (en appliquant un filtre de Henderson de 13 termes) et pour la méthode FST, un quadrillage du plan est réalisé avec un pas de <span class="math inline">\(0,05\)</span> et avec comme contraintes linéaires la préservation des polynômes de degrés 0 à 3.
Trois critères de qualité sont également calculés :</p>
<ol style="list-style-type: decimal">
<li><p>Calcul du déphasage dans la détection des points de retournement. La définition <span class="citation"><a href="#ref-Zellner1991" role="doc-biblioref">Zellner, Hong, et Min</a> (<a href="#ref-Zellner1991" role="doc-biblioref">1991</a>)</span> est utilisée pour déterminer les points de retournement :</p>
<ul>
<li>on parle de redressement (<em>upturn</em>) lorsque l’on passe d’une phase de récession à une phase d’expansion de l’économie.
C’est le cas à la date <span class="math inline">\(t\)</span> lorsque <span class="math inline">\(y_{t-3}\geq y_{t-2}\geq y_{t-1}&lt;y_t\leq y_{t+1}\)</span>.<br />
</li>
<li>on parle de ralentissement (<em>downturn</em>) lorsque l’on passe d’une phase d’expansion à une phase de récession.
C’est le cas à la date <span class="math inline">\(t\)</span> lorsque <span class="math inline">\(y_{t-3}\leq y_{t-2}\leq y_{t-1}&gt;y_t\geq y_{t+1}\)</span>.</li>
</ul>
<p>Le déphasage est souvent définit comme le nombre de mois nécessaires pour détecter le bon point de retournement (i.e., le point de retournement sur la composante cyclique).
Nous utilisons ici un critère légèrement modifié : le déphasage est définit comme le nombre de mois nécessaires pour détecter le bon point de retournement sans aucune révision future.
Il peut en effet arriver que le bon point de retournement soit détecté par des filtres asymétriques mais ne le soit pas avec l’estimation finale avec un filtre symétrique (c’est le cas de 41 points de retournements sur l’ensemble des 9 séries avec les filtres asymétriques de Musgrave) ou qu’il y ait des révisions dans les estimations successives (c’est le cas de 7 points de retournements sur l’ensemble des 9 séries avec les filtres asymétriques de Musgrave).
Finalement, relativement peu de points de retournement sont détectés à la bonne date avec l’estimation finale.
Avec le filtre de Henderson de 13 termes, 18 sont correctement détectés sur les séries avec une faible variabilité (sur les 57 possibles), 11 sur les séries à variabilité moyenne et 12 sur les séries à forte variabilité.</p></li>
<li><p>Calcul de deux critères de révisions : la moyenne des écarts relatifs entre la <span class="math inline">\(q\)</span> estimation et la dernière estimation <span class="math inline">\(MAE_{fe}(q)\)</span> et la moyenne des écarts relatifs entre la <span class="math inline">\(q\)</span> et la <span class="math inline">\(q+1\)</span> estimation <span class="math inline">\(MAE_{qe}(q)\)</span>
<span class="math display">\[
MAE_{fe}(q)=\mathbb E\left[
\left|\frac{
y_{t|t+q} -  y_{t|last}
}{
 y_{t|last}
}\right|
\right]
\quad\text{et}\quad
MAE_{qe}(q)=\mathbb E\left[
\left|\frac{
y_{t|t+q} - y_{t|t+q+1}
}{
y_{t|t+q+1}
}\right|
\right]
\]</span></p></li>
</ol>
</div>
<div id="séries-simulées" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Séries simulées</h2>
<div id="comparaison-des-filtres-polynomiaux-locaux-et-des-filtres-rkhs" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Comparaison des filtres polynomiaux locaux et des filtres RKHS</h3>
<p>Du fait du fort degré de liberté de l’approche FST (dans le choix des différents paramètres), dans cette section, on ne compare les méthodes issues l’approche polynomiale locale utilisant le noyau de Henderson<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> et les filtres RKHS <span class="math inline">\(b_{q,\Gamma}\)</span>, <span class="math inline">\(b_{q,G}\)</span> et <span class="math inline">\(b_{q,\varphi}\)</span>.</p>
<p>En termes de déphasage dans la détection des points de retournement, c’est le filtre <span class="math inline">\(b_{q,G}\)</span> qui semble donner les meilleurs résultats quelle que soit la variabilité de la série (figure <a href="sec-comparison.html#fig:graphstpsimul">6.1</a>), avec des performances légèrement meilleurs que celles obtenues en prolongeant la série grâce à un modèle ARIMA.
Étonnement, c’est le filtre <span class="math inline">\(b_{q,\varphi}\)</span> qui minimise le déphasage qui donne les moins bons résultats. Cela peut s’expliquer par le fait que la courbe des coefficients des moyennes mobiles asymétriques sont assez éloignées des coefficients du filtre symétrique : il y a donc potentiellement beaucoup de révisions dans la détection des points de retournement.
Dans les filtres polynomiaux locaux, les filtres LC (filtres de Musgrave) semblent donner les meilleurs résultats lorsque la variabilité est moyenne ou forte (avec des résultats proches du filtre QL dans ce second pas) mais de moins bons résultats lorsque la variabilité est faible.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:graphstpsimul"></span>
<img src="img/simulations/phase_shift_simul.svg" alt="Distribution des déphasages sur les séries simulées." width="100%" />
<p class="caption">
Figure 6.1 : Distribution des déphasages sur les séries simulées.
</p>
</div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:simulrev">Table 6.1 : </span>Moyenne des écarts relatifs des révisions pour les différents filtres sur les séries à variabilité moyenne.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Méthode
</th>
<th style="text-align:center;">
<span class="math inline">\(q=0\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(q=1\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(q=2\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(q=3\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(q=4\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(q=5\)</span>
</th>
</tr>
</thead>
<tbody>
<tr grouplength="8">
<td colspan="7" style="border-bottom: 1px solid;">
<strong><span class="math inline">\(MAE_{fe}(q) = \mathbb E\\left[\\left|(y_{t|t+q} - y_{t|last})/y_{t|last}\\right|\\right]\)</span></strong>
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
LC
</td>
<td style="text-align:center;">
0,21
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
QL
</td>
<td style="text-align:center;">
0,33
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,04
</td>
<td style="text-align:center;">
0,04
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
CQ
</td>
<td style="text-align:center;">
0,45
</td>
<td style="text-align:center;">
0,13
</td>
<td style="text-align:center;">
0,13
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,06
</td>
<td style="text-align:center;">
0,02
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
DAF
</td>
<td style="text-align:center;">
0,47
</td>
<td style="text-align:center;">
0,15
</td>
<td style="text-align:center;">
0,15
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,06
</td>
<td style="text-align:center;">
0,02
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,\Gamma}\)</span>
</td>
<td style="text-align:center;">
0,63
</td>
<td style="text-align:center;">
0,21
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,04
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,G}\)</span>
</td>
<td style="text-align:center;">
0,83
</td>
<td style="text-align:center;">
0,37
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,04
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,\varphi}\)</span>
</td>
<td style="text-align:center;">
0,31
</td>
<td style="text-align:center;">
0,11
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,05
</td>
<td style="text-align:center;">
0,07
</td>
<td style="text-align:center;">
0,09
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
ARIMA
</td>
<td style="text-align:center;">
0,22
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
<tr grouplength="8">
<td colspan="7" style="border-bottom: 1px solid;">
<strong><span class="math inline">\(MAE_{ce}(q)=\mathbb E\\left[ \\left|(y_{t|t+q} - y_{t|t+q+1})/y_{t|t+q+1}\\right| \\right]\)</span></strong>
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
LC
</td>
<td style="text-align:center;">
0,19
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,02
</td>
<td style="text-align:center;">
0,01
</td>
<td style="text-align:center;">
0,07
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
QL
</td>
<td style="text-align:center;">
0,29
</td>
<td style="text-align:center;">
3,46
</td>
<td style="text-align:center;">
0,00
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,04
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
CQ
</td>
<td style="text-align:center;">
0,43
</td>
<td style="text-align:center;">
0,02
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,07
</td>
<td style="text-align:center;">
0,05
</td>
<td style="text-align:center;">
0,02
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
DAF
</td>
<td style="text-align:center;">
0,66
</td>
<td style="text-align:center;">
0,24
</td>
<td style="text-align:center;">
0,11
</td>
<td style="text-align:center;">
0,14
</td>
<td style="text-align:center;">
0,06
</td>
<td style="text-align:center;">
0,02
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,\Gamma}\)</span>
</td>
<td style="text-align:center;">
0,38
</td>
<td style="text-align:center;">
0,32
</td>
<td style="text-align:center;">
0,09
</td>
<td style="text-align:center;">
0,00
</td>
<td style="text-align:center;">
0,41
</td>
<td style="text-align:center;">
0,04
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,G}\)</span>
</td>
<td style="text-align:center;">
0,70
</td>
<td style="text-align:center;">
0,46
</td>
<td style="text-align:center;">
0,10
</td>
<td style="text-align:center;">
0,00
</td>
<td style="text-align:center;">
0,43
</td>
<td style="text-align:center;">
0,04
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
<span class="math inline">\(b_{q,\varphi}\)</span>
</td>
<td style="text-align:center;">
0,22
</td>
<td style="text-align:center;">
0,16
</td>
<td style="text-align:center;">
0,08
</td>
<td style="text-align:center;">
0,05
</td>
<td style="text-align:center;">
0,03
</td>
<td style="text-align:center;">
0,09
</td>
</tr>
<tr>
<td style="text-align:center;padding-left: 2em;" indentlevel="1">
ARIMA
</td>
<td style="text-align:center;">
0,21
</td>
<td style="text-align:center;">
0,13
</td>
<td style="text-align:center;">
0,02
</td>
<td style="text-align:center;">
0,02
</td>
<td style="text-align:center;">
0,25
</td>
<td style="text-align:center;">
0,01
</td>
</tr>
</tbody>
</table>
<p>Concernant les révisions, la variabilité de la série a peu d’impact sur les performances respectives des différentes méthodes mais joue sur les ordres de grandeurs.
Globalement, les filtres LC minimisent toujours les révisions (voir tableau <a href="sec-comparison.html#tab:simulrev">6.1</a>) et les révisions sont plus importantes avec les filtres CQ, DAF et les filtres RKHS autres que <span class="math inline">\(b_{q,\varphi}\)</span>.
Pour les filtres QL, il y a une forte révision entre la deuxième et la troisième estimation : cela peut venir du fait que pour la deuxième estimation (lorsque l’on connait un point dans le futur), le filtre QL associe un poids plus important à l’estimation en <span class="math inline">\(t+1\)</span> qu’à l’estimation en <span class="math inline">\(t\)</span>, ce qui crée une discontinuité.
Pour les filtres polynomiaux autres que le filtre LC, les révisions importantes à la première estimation étaient prévisibles au vu de la courbe des coefficients : un poids très important est associé à l’observation courante et il y une forte discontinuité entre la moyenne mobile utilisée pour l’estimation en temps réelle (lorsqu’aucun point dans le futur n’est connu) et les autres moyennes mobiles.</p>
<p>Le prolongement de la série par un modèle ARIMA donnent révisions avec les dernières estimations du même ordre de grandeur que le filtre LC mais des révisions plus importantes entre les estimations consécutives (on pouvait s’y attendre comme souligné dans la section <a href="sec-propMM.html#subec:mmetprev">2.3.1</a>).</p>
<p>En somme, par rapport au filtre LC, la réduction du déphasage du filtre <span class="math inline">\(b_{q,G}\)</span> se fait au coût de révisions 4 fois plus importantes lorsque la variabilité de la série est moyenne.
Pour les séries à forte variabilité, les révisions sont du même ordre de grandeur mais l’écart est bien plus important pour les séries à faible variabilité.</p>
</div>
<div id="comparaison-avec-lapproche-fst" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Comparaison avec l’approche FST</h3>
<p>Pour le choix des poids dans l’approche FST, l’idée retenue dans cette étude est de faire un quadrillage du plan <span class="math inline">\([0,1]^3\)</span> avec un pas de 0,05 et en imposant <span class="math inline">\(\alpha + \beta + \gamma = 1\)</span><a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a>.
Pour chaque combinaison de poids, quatre ensembles de moyennes mobiles sont construits en forçant dans la minimisation la préservation de polynômes de degré 0 à 3.
Le filtre symétrique utilisé est toujours celui de Henderson.
Ces différentes moyennes mobiles sont ensuite comparées relativement aux performances des filtres LC et, par simplification, uniquement sur les séries simulées à variabilité moyenne.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:graphstpsimulfst"></span>
<img src="img/simulations/fst_mediumvariability_tp_med.svg" alt="Médiane du déphasage relatif des filtres FST par rapport au filtre LC selon les poids sur les séries simulées à variabilité moyenne." width="90%" />
<p class="caption">
Figure 6.2 : Médiane du déphasage relatif des filtres FST par rapport au filtre LC selon les poids sur les séries simulées à variabilité moyenne.
</p>
</div>
<p>En termes de déphasage, en médiane, les filtres qui sont plus performants que les filtres LC sont ceux qui préservent le polynômes de degré 2 et ayant un poids associé à la <em>fidelity</em> (<span class="math inline">\(\beta\)</span>) inférieur à 0,5 et ceux qui préservent les polynômes de degré 3 (figure <a href="sec-comparison.html#fig:graphstpsimulfst">6.2</a>).
En revanche, une analyse plus fine des résultats montre qu’en moyenne le déphasage est plus élevé qu’avec la méthode LC pour tous les filtres FST mais les résultats sont quasiment équivalents (entre 1,0 et 1,1) pour les filtres qui préservent les polynômes de degré 2 avec <span class="math inline">\(\alpha = \beta =0,05\)</span> et <span class="math inline">\(\alpha = 0,05, \, \beta =0\)</span> et ceux qui préservent les polynômes de degré 3 avec <span class="math inline">\(\beta=0\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:graphsfeq0simulfst"></span>
<img src="img/simulations/fst_mediumvariability_fe_q0.svg" alt="Moyenne des écarts relatifs des révisions entre la première et la dernière estimation ($MAE_{fe}(0)$), comparativement aux révisions du filtre LC sur les séries à variabilité moyenne." width="90%" />
<p class="caption">
Figure 6.3 : Moyenne des écarts relatifs des révisions entre la première et la dernière estimation (<span class="math inline">\(MAE_{fe}(0)\)</span>), comparativement aux révisions du filtre LC sur les séries à variabilité moyenne.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:graphsceq0simulfst"></span>
<img src="img/simulations/fst_mediumvariability_ceq0.svg" alt="Moyenne des écarts relatifs des révisions entre la première et la deuxième estimation ($MAE_{ce}(0)$), comparativement aux révisions du filtre LC sur les séries à variabilité moyenne." width="90%" />
<p class="caption">
Figure 6.4 : Moyenne des écarts relatifs des révisions entre la première et la deuxième estimation (<span class="math inline">\(MAE_{ce}(0)\)</span>), comparativement aux révisions du filtre LC sur les séries à variabilité moyenne.
</p>
</div>
<p>En termes de révisions (figures <a href="sec-comparison.html#fig:graphsfeq0simulfst">6.3</a> et <a href="sec-comparison.html#fig:graphsceq0simulfst">6.4</a>), les révisions entre la première et dernière estimation et entre la première et deuxième estimation sont inférieures à celles du filtre LC lorsque les filtres préservent les polynômes de degré 1. En revanche, avec les filtres qui préserve les polynômes de degré 3 les révisions entre la première et dernière estimation sont en moyenne plus de deux fois plus importante qu’avec le filtre LC et sont modérément plus élevées (rapport entre 1 et 2).</p>
<p>En somme, même si une étude plus approfondie devrait être menée, pour l’étude de la méthode FST il parait opportun de se concentrer sur les filtres qui préserve les polynômes de degré 2 avec un poids associé au critère <em>fidelity</em> élevé et un poids faible associé au critère <em>smoothness</em>.</p>
</div>
</div>
<div id="série-réelle" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Série réelle</h2>
<p>Les différentes méthodes sont également comparées sur le point de retournement d’avril 2020 sur les ventes au détail des États-Unis (série <code>RETAILx</code> de la base FRED-MD <span class="citation"><a href="#ref-fredmd" role="doc-biblioref">McCracken et Ng</a> (<a href="#ref-fredmd" role="doc-biblioref">2016</a>)</span>, utilisée en logarithme).
C’est une série avec une variabilité moyenne.
Les résultats des différentes estimations sont tracées dans les figures <a href="sec-comparison.html#fig:retailxlp">6.5</a> à <a href="sec-comparison.html#fig:retailxfst2">6.8</a>.
Pour l’approche FST, on ne retient que les filtres obtenus avec les poids <span class="math inline">\(\begin{pmatrix}\alpha&amp;\beta&amp;\gamma\end{pmatrix} = \begin{pmatrix}0,05 &amp;0,00&amp;0,95\end{pmatrix},\, \begin{pmatrix}0,00 &amp;0,05&amp;0,95\end{pmatrix},\, \begin{pmatrix}0,05 &amp;0,05&amp;0,90\end{pmatrix}\)</span> ou <span class="math inline">\(\begin{pmatrix}0 &amp;0&amp;1\end{pmatrix}\)</span> et en préservant les tendances de degré 2 ou 3.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:retailxlp"></span>
<img src="img/nber/retailx_lp.svg" alt="Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec les méthodes polynomiales locales." width="90%" />
<p class="caption">
Figure 6.5 : Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec les méthodes polynomiales locales.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:retailxrkhs"></span>
<img src="img/nber/retailx_rkhs_arima.svg" alt="Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec les RKHS et en prolongeant la série par modèle ARIMA." width="90%" />
<p class="caption">
Figure 6.6 : Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec les RKHS et en prolongeant la série par modèle ARIMA.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:retailxfst1"></span>
<img src="img/nber/retailx_fstp1.svg" alt="Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec la méthode FST et $\begin{pmatrix}\alpha&amp;\beta&amp;\gamma\end{pmatrix} = \begin{pmatrix}0,05 &amp;0,00&amp;0,95\end{pmatrix}$ ou $\begin{pmatrix}0,05 &amp;0,05&amp;0,90\end{pmatrix}$." width="90%" />
<p class="caption">
Figure 6.7 : Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec la méthode FST et <span class="math inline">\(\begin{pmatrix}\alpha&amp;\beta&amp;\gamma\end{pmatrix} = \begin{pmatrix}0,05 &amp;0,00&amp;0,95\end{pmatrix}\)</span> ou <span class="math inline">\(\begin{pmatrix}0,05 &amp;0,05&amp;0,90\end{pmatrix}\)</span>.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:retailxfst2"></span>
<img src="img/nber/retailx_fstp2.svg" alt="Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec la méthode FST et $\begin{pmatrix}\alpha&amp;\beta&amp;\gamma\end{pmatrix} =\begin{pmatrix}0,00 &amp;0,05&amp;0,95\end{pmatrix}$ ou $\begin{pmatrix}0 &amp;0&amp;1\end{pmatrix}$." width="90%" />
<p class="caption">
Figure 6.8 : Estimations successives de la tendance-cycle des ventes au détail aux États-Unis avec la méthode FST et <span class="math inline">\(\begin{pmatrix}\alpha&amp;\beta&amp;\gamma\end{pmatrix} =\begin{pmatrix}0,00 &amp;0,05&amp;0,95\end{pmatrix}\)</span> ou <span class="math inline">\(\begin{pmatrix}0 &amp;0&amp;1\end{pmatrix}\)</span>.
</p>
</div>
<p>Même si presque toutes les méthodes ont un déphasage d’au plus 3 mois sur ce point de retournement, les estimations intermédiaires différent grandement.
Il y a par exemple nettement plus de variabilités dans les estimations en temps réel pour les méthode QL, CQ et DAF et les filtres FST (figures <a href="sec-comparison.html#fig:retailxlp">6.5</a>, <a href="sec-comparison.html#fig:retailxfst1">6.7</a> et <a href="sec-comparison.html#fig:retailxfst2">6.8</a>), avec des estimations intermédiaires qui semblent peu plausibles (notamment pour la première estimation du mois d’avril 2020). Les premières estimations avec le filtre LC ne capte pas la remontée en mai et juin 2020 : cela peut provenir du fait qu’en fin de série, la tendance modélisée est linéaire.
Concernant les filtres RKHS, les estimations intermédiaires du filtre <span class="math inline">\(b_{q,\varphi}\)</span> semblent très erratiques, ce qui s’explique par le fait que les moyennes mobiles asymétriques utilisées lorsque l’on se rapproche du cas symétrique sont éloignées de la moyenne mobile symétrique d’Henderson.
En revanche, les filtres <span class="math inline">\(b_{q,\Gamma}\)</span> et <span class="math inline">\(b_{q,G}\)</span> donnent des estimations intermédiaires proches de l’estimation finale, tout en minimisant le déphasage.</p>
<p>La qualité des estimations intermédiaires peut également être analysée grâces aux prévisions implicites des différentes méthodes. Pour rappel, il s’agit des prévisions de la série brute qui, en appliquant le filtre symétrique de Henderson sur la série prolongée, donne les mêmes estimations que les moyennes mobiles asymétriques. L’annexe <a href="an-implicitforecasts.html#an-implicitforecasts">D</a> rassemble les différentes prévisions implicites des filtres étudiés dans cette section.
Les prévisions implicites des filtres polynomiaux autres que LC, des filtres FST et du filtre <span class="math inline">\(b_{q,\varphi}\)</span> sont très peu plausibles et très éloignés des valeurs futures.
Le contrecoup en mai 2020 suite à la baisse d’avril 2020 ne sont pas prévus par le modèle ARIMA mais le sont par les filtres LC et RKHS, en revanche, les prévisions à l’horizon de 6 mois peuvent être assez éloignées des valeurs attendues.</p>
<div style="page-break-after: always;"></div>

</div>
</div>
<h3>Références</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DarneDagum2009" class="csl-entry">
Darne, Olivier, et Estelle Bee Dagum. 2009. <span>« <span>Performance of short-term trend predictors for current economic analysis</span> »</span>. <em>Economics Bulletin</em> 29 (1): 79‑89.
</div>
<div id="ref-fredmd" class="csl-entry">
McCracken, Michael W., et Serena Ng. 2016. <span>« FRED-MD: A Monthly Database for Macroeconomic Research »</span>. <em>Journal of Business &amp; Economic Statistics</em> 34 (4): 574‑89. <a href="https://doi.org/10.1080/07350015.2015.1086655">https://doi.org/10.1080/07350015.2015.1086655</a>.
</div>
<div id="ref-Zellner1991" class="csl-entry">
Zellner, Arnold, Chansik Hong, et Chung-ki Min. 1991. <span>« Forecasting turning points in international output growth rates using Bayesian exponentially weighted autoregression, time-varying parameter, and pooling techniques »</span>. <em>Journal of Econometrics</em> 49 (1-2): 275‑304. <a href="https://EconPapers.repec.org/RePEc:eee:econom:v:49:y:1991:i:1-2:p:275-304">https://EconPapers.repec.org/RePEc:eee:econom:v:49:y:1991:i:1-2:p:275-304</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="23">
<li id="fn23"><p>Le modèle ARIMA est déterminé automatiquement en n’utilisant pas de retard saisonnier (les séries étant désaisonnalisées) et en n’utilisant aucune variable extérieure (comme des régresseurs de correction des points atypiques).<a href="sec-comparison.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>
Il est en effet difficile de comparer proprement les résultats entre les différents noyaux car le filtre symétrique n’est pas le même. Cela a pour conséquence que des points de retournement peuvent être détectés. Par exemple, pour le filtre LC, sur les trois séries ayant une variabilité moyenne, seul 1 point de retournement est correctement détecté par l’ensemble des noyaux.
Toutefois, une première analyse des résultats montrent que les différents noyaux ont des performances proches en termes de déphasage et de révisions, sauf le noyau uniforme qui produit de moins bons résultats.<a href="sec-comparison.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>
Comme il n’est pas possible d’avoir un poids associé à la <em>timeliness</em> (<span class="math inline">\(\gamma\)</span>) égale à 1 (sinon la fonction objectif n’est pas strictement convexe), on construit également un filtre avec un poids très proche de 1 (<span class="math inline">\(1-1/1000\)</span>).<a href="sec-comparison.html#fnref25" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sec-nonparamreg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["AQLT_JMS_2022.pdf", "AQLT_JMS_2022.docx", "AQLT_JMS_2022.tex"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
